---
layout: post
title: Go in 42 lines of Ruby
published: true
author: Julien Letessier
author_role: Software Engineer
author_url: http://github.com/mezis
author_avatar: http://www.gravatar.com/avatar/88683f31bdf05a8071fb08327b3919cb
summary: |
  Go's Goroutines are like sugar. They give me a rush, and my IO-bound work as
  well!

  But for a one-off script, my Go's not fluent enough, so why not bring some of
  it to Ruby?

  Read on for a no-frills approach to `go { do_stuff }`.
---

> Go's Goroutines are like sugar. They give me a rush, and my IO-bound work as
> well!

> But for a one-off script, my Go's not fluent enough, so why not bring some of
> it to Ruby?

I'm writing a script that scrapes a slow API pretty intensely.
The naive approach would have me to this:

{% highlight ruby %}
things_ids.each do |thing_id|
  data = HttpClient.get("http://example.com/things/#{thing_id}")
  save_to_file(data)
end
{% endhighlight %}

...but I have 3,000 things to get, the API takes 1 second per call, and I'm not
that patient.

(for the record, the API in question is Pivotal Tracker's)

So what I'd really like to do is something like:

{% highlight ruby %}
things_ids.each do |thing_id|
  go { HttpClient.get("http://example.com/things/#{thing_id}") }
end
{% endhighlight %}

and have it magically parallelize.

Sure, I could use Celluloid's [beautiful
futures](https://github.com/celluloid/celluloid/wiki/Futures), or Faraday's
[parallelism
support](https://github.com/lostisland/faraday/wiki/Parallel-requests), but
today I have a moment to tinker under the hood.

All I really need is a pool of threads, futures, and some syntax sugar:

{% highlight ruby %}
class Pool
  def initialize(max_size = nil)
    @threads = []
    @lock    = Monitor.new
    @signal  = ConditionVariable.new(@lock)
    @max_size = max_size
  end

  def go(&block)
    @lock.synchronize do
      @signal.wait while !available?
      @threads << Thread.new do
        Thread.current.abort_on_exception = true

        begin
          value = block.call
        ensure
          release Thread.current
        end
        value
      end
      return @threads.last
    end
  end

  private

  def release(thread)
    @lock.synchronize do
      @threads.delete thread
      @signal.broadcast
    end
  end

  def available?
    @max_size.nil? || @threads.length < @max_size
  end
end
{% endhighlight %}


Our pool just has one `go` method. Pass it a block, and it will spawn a thread
to do your work (possibly waiting on the pool to have a free slot).

`abort_on_exception` makes sure that if one of your "goroutines" bursts into
flames, you're told (as opposed to the default of failing silently).

The `@lock` / `@signal` dance keeps your pool size is under control;
specifically the `@signal` will wake up waiting for a slot in the pool whenever
one becomes available.

Threads in Ruby can be used as promises/futures, and the `go` method returns a
thread object (leaky API, but bear with me):

{% highlight ruby %}
go { :hello }.value
#=> :hello
{% endhighlight %}

There's two big caveats here, so please don't do this in production codeâ€”experts
have built better libraries for this, this is for educational purposes, don't
say you weren't warned:

- This is bloody hard to integration test, as is everything with threads and
  parallelism.
- If you limit the pool size, you'll get deadlocks rapidly unless you very
  carefully think about what you're spawning.
- If you don't, your machine may or may not catch fire (or in my case, your API
  token may well get banned!)

I almost forgot the syntax sugar that lets you say `go` in your
[favourite](https://github.com/pry/pry) Ruby REPL:

{% highlight ruby %}
def Kernel.go(&block)
  ($pool ||= Pool.new).go(&block)
end
{% endhighlight %}

